---
title: Avoiding TikTok's auto moderation
date: 09/11/2020
abstract: Nobody outside of TikTok understands how it explicitly works. Users have taken
tags: technology, human-computer interaction
---

### Preamble

TikTok is some what of a black box. At a glance, it's simple -- it's an algorithm that is fed a *swarth* of data about a user to provide a customized feed. But once you start interacting with the app, and espeically, start creating content on the app, you begin to realize you're in the dark.

A majority of creators will say the following at least once: "I've been shadowbanned, if you see this video please interact with it!"

Because a creator's outreach is soley decided and execute by TikTok, creators experience periods of amazing growth and "virality". Then, almost at random, this can be taken away. Creators have begun to refer to this as being shadowbanned. Based on what they've observerd and how consumption in the app works, the obvious solution is to ask viewers to interact with you content; somehow feed the algorithm positive queues about your content.

As an aside, one of my favorite calls to action I've seen is "Hit share -> other -> copy link". This is because, I assume, TikTok doesn't know how to weight that interaction. They override buttons for sharing via messages, snapchat, twitter, etc. but once you hit other (and open the system default share sheet) they can't track what you do from there. All they can see is success or failure. If you copy the link, it's a "success"; if you hit cancel, it's a "failure".

---

### Avoiding auto moderation 

That has very little to do with what I'm writing about today but it sets a good stage. Creators walk on egg shells to avoid upsetting the algorithm -- they don't want to send any wrong signals. From a Human-Computer Interaction point of view this is amazing but, again, not directly related to the following.

The following are assumptions made by users (myself included) and not hard truths.

To prevent a shadow ban or outright content take down, creators use aliases for "bad words" to throw the algorithm off.

Here are some of my favorite examples:
